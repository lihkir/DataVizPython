{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definición:**\n",
    "Un **proceso estocástico** es una colección o familia de variables aleatorias $\\{X_{t}\\}_{t\\in I}$ ordenadas según el subíndice $t$ que en general se suele identificar con el tiempo. Llamamos trayectoria del proceso a una realización del proceso estocástico. Si $I$ es discreto, el proceso es en tiempo discreto. Si $I$ es continuo, el proceso es en tiempo continuo.\n",
    "\n",
    "- **Observación:** \n",
    "    - *Por tanto, para cada instante $t$ tendremos una variable aleatoria distinta representada por $X_{t}$, con lo que un proceso estocástico puede interpretarse como una sucesión de variables aleatorias cuyas características pueden variar a lo largo del tiempo.*\n",
    "    - *Un ejemplo de proceso en tiempo discreto se obtiene para $I = \\{1,\\dots,n\\}$. En este caso, el proceso es $Y_{1}, Y_{2},\\dots, Y_{n}$, y una trayectoria se denota por $y_{1}, y_{2},\\dots, y_{n}$. Un ejemplo de proceso en tiempo continuo se obtiene para $I=[0, T], I=[0,\\infty], I=(-\\infty,\\infty)$*\n",
    "\n",
    "- **Definición:** Una **serie temporal** es una realización parcial de un proceso estocástico de parámetro tiempo discreto, donde los elementos de $I$ están ordenados y corresponden a instantes equidistantes del tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{figure} ./figures/stochastic_process.png\n",
    ":name: stochastic_process_fig\n",
    ":align: center\n",
    ":scale: 45\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definición:** Un proceso estocástico $(Y_{t})$ es **estacionario** cuando las propiedades estadísticas de cualquier secuencia finita $Y_{t_{1}}, Y{t_{2}},\\dots, Y{t_{n}}, (n\\geq1)$ de componentes de $(Y_{t})$ son semejantes a las de la secuencia $Y_{t_{1}+h}, Y_{t_{2}+h},\\dots, Y_{t_{n}+h}$ para cualquier número entero $h = \\pm1, \\pm2,\\dots$\n",
    "\n",
    "- **Definición:** Un proceso estocástico $(Y_{t})$ es **no estacionario** cuando las propiedades estadísticas de al menos una secuencia finita $Y_{t_{1}}, Y{t_{2}},\\dots, Y{t_{n}}, (n\\geq1)$ de componentes de $(Y_{t})$, son diferentes de las de la secuencia $Y_{t_{1}+h}, Y_{t_{2}+h},\\dots, Y_{t_{n}+h}$ para al menos un número entero $h>0$.\n",
    "\n",
    "- **Definición:** La covarianza entre $y_{t}$ y su valor en otro periodo de tiempo, digamos, $y_{t+k}$ se denomina **autocovarianza** en el retardo $k$, y se define como\n",
    "  \n",
    "$$\\gamma_{k}=\\text{Cov}(y_{t}, y_{t+k})=\\text{E}[(y_{t}-\\mu)(y_{t+k}-\\mu)]$$\n",
    "\n",
    "- La colección de los valores de $\\gamma_{k}, k = 0, 1, 2,\\dots$ se denomina función de autocovarianza. Obsérvese que la autocovarianza en el lag $k = 0$ es simplemente la varianza de la serie temporal; es decir, $\\gamma_{0} = \\sigma_{y}^{2}$, que es constante para una serie temporal estacionaria. El coeficiente de autocorrelación en el lag $k$ para una serie temporal estacionaria es\n",
    "\n",
    "$$\\rho_{k}=\\frac{\\text{E}[(y_{t}-\\mu)(y_{t+k}-\\mu)]}{\\sqrt{\\text{E}[(y_{t}-\\mu)^{2}]\\text{E}[(y_{t+k}-\\mu)^{2}]}}=\\frac{\\text{Cov}(y_{t}, y_{t+k})}{\\text{Var}(y_{t})}=\\frac{\\gamma_{k}}{\\gamma_{0}}$$\n",
    "\n",
    "- La colección de los valores de $\\rho_{k}, k = 0, 1, 2,\\dots$ se llama **función de autocorrelación (ACF)**. La función `ACF` *puede ser utilizada para seleccionar el orden* $q$ *de un modelo* `MA(q)`.\n",
    "\n",
    "- **Definición:** Un **modelo** para un proceso estocástico es cualquier conjunto de hipótesis bien definidas sobre las propiedades estadísticas de dicho proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al modelo ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los modelos **`ARIMA (Autorregresivo integrado de media móvil)`** aproximan los valores futuros de una serie temporal como una función lineal de observaciones pasadas y términos de ruido blanco. Una serie de tiempo $y_{t}$ se llama un proceso de media móvil integrada autorregresiva (ARIMA) de órdenes $p, d$, y $q$, denotado ARIMA($p, d, q$) si su diferencia $d$ da lugar a un proceso estacionario ARMA($p, q$). Por lo tanto, un ARIMA($p, d, q$) puede escribirse como\n",
    "\n",
    "    $$\\Phi(B)(1-B)^{d}y_{t}=\\delta+\\Theta(B)\\varepsilon_{t}$$\n",
    "    \n",
    "    where\n",
    "    \n",
    "    $$\\Phi(B)=1-\\sum_{i=1}^{p}\\phi_{i}B^{i}\\quad\\text{and}\\quad\\Theta(B)=1-\\sum_{i=1}^{q}\\theta_{i}B^{i},$$\n",
    "    \n",
    "    son los términos del operador back-shit en los AR($p$) y MA($q$) definidos como $\\Phi(B)y_{t}=\\delta+\\varepsilon_{t}$ y $y_{t}=\\mu+\\Theta(B)\\varepsilon_{t}$, con $\\delta=\\mu-\\phi\\mu$, donde $\\mu$ es la media y $\\varepsilon_{t}$ el ruido blanco con $E(\\varepsilon_{t})=0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Así, una vez realizada la diferenciación y una serie temporal estacionaria $w_{t}=(1-B)^{d}y_{t}$ es obtenida, los métodos *autoregresivo* de orden $p$: AR($p$) y *media movil*  de orden $q$: MA($q$) pueden ser aplicados para tener un modelo completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación del modelo ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Durante esta sección estudiaremos el uso de las **APIs** para cargar datos de interes de estudio, los cuales en esta sección corresponden a series de tiempo financieras, especificamente la serie de tiempo de las acciones de **Apple** cotizadas en bolsas de valores será considerada. \n",
    "- En las secciones pasadas los datos eran cargados a un `DataFrame` usando la función `read_csv` de **Python** utlizando el link de `github` en formato `raw` o simplemente con la dirección del directorio local donde reposaba el archivo en formato *CSV* que deseabamos cargar, en éste caso utlizaremos un protocolo de internet intermediario que nos permitirá obtener dichos datos. \n",
    "- Las series de tiempo financieras son de gran interés personal, pero estos modelos pueden ser aplicados a cualquier tipo de proceso discreto que requiera de predicciones para la correcta toma de decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Qué es una API?** **API** es el acrónimo de **Application Programming Interface** (Interfaz de Programación de Aplicaciones), que es un intermediario de software que permite que dos aplicaciones se comuniquen entre sí. Cada vez que usas una aplicación como Facebook, envías un mensaje instantáneo o consultas el tiempo en tu teléfono, estás usando una API. En su mayoría las **API** son privadas, algunas como la de `yahoo finance` son libres hasta cierto límite, y para cierto `futuros` y `derivados` especificos. Algunas entregan una versión de prueba, luego cuando la compañia que la ofrece nota un gran número de consultas (`queries`) por medio de su **API** a sus servidores desde una **IP** determinada, o de un `Bot` por ejemplo que hayas programado, comienzas a obtener mensajes de error direccionados a tu **IP** revocando la conexión. Otra opción interesante es `Quandl`, pero desafortunadamente ahora es adquisición de `Nasdaq` y lo más seguro es que exisitrán ciertos costos para el uso de la **API** que no existian antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una opción gratuita, en el caso de que no desee pagar por los servicios de APIs tales como la de finnhub, es *Yahoo Finance*. En esta sección estudiaremos como hacer uso de la *API de Yahoo Finance* y además, como podemos descargar la *información necesaria para un EDA* y graficos de velas por ejemplo.\n",
    "\n",
    "- Descargaremos para este ejemplo los datos de las acciones de **Apple** utilizando la API de yahoo Finance. Para esto debe primero que todo, debe instalar la librería que le permitirá hacer uso de API\n",
    "\n",
    "````python\n",
    "pip install yfinance\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para usar la API, solo tiene que crear un objeto **ticker** con su respectivo símbolo, y luego puede realizar simples *queries* a métodos en el objeto que devuelven todo lo necesario par analizar series de tiempo financieras. Si usamos la función `.info()` podemos acceder a toda la información que podemos consultar sobre una acción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = yf.Ticker(\"AAPL\")\n",
    "msft.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `yahoo_fin` es otra biblioteca de código abierto completamente gratuita similar a `yfinance`, desarrollada por el autor de [theautomatic](https://theautomatic.net/). Carece de análisis de mercado/noticias, aunque ofrece una buena gama de datos de fundamentos y opciones. Puede consutlar cada uno de los atributos de esta librería, a los cuale puede hacer en [yahoo_fin-documentation](https://theautomatic.net/yahoo_fin-documentation/). Para instalarla utilice la siguiente orden:\n",
    "\n",
    "````shell\n",
    "pip install yahoo_fin\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `yahoo_fin` también tiene algunas dependencias: `ftplib, io, pandas, requests, requests_html`. Con la exsepción de `requests_html`, todos ellos deberían venir preinstalados con `miniconda`. Para instalar `requests_html` utilice:\n",
    "\n",
    "````shell\n",
    "pip install requests_html\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para descargar datos históricos utilizando la biblioteca `yahoo_fin`, el método a utilizar es es `get_data()`. Tendremos que *importarlo desde el módulo* `stock_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta función toma los argumentos\n",
    "\n",
    "    - `ticker`: ticker de la acción/bono deseado, sin distinción entre mayúsculas y minúsculas\n",
    "    - `start_date`: fecha de inicio de los datos (mm/dd/aaaa)\n",
    "    - `end_date`: fecha en la que desea que finalicen los datos (mm/dd/aaaa)\n",
    "    - `index_as_date`: {True, False}. Por defecto es `True`. Si es `True` entonces las fechas de los registros se establecen como el índice, de lo contrario se devuelven como una columna separada.\n",
    "    - `interval`: {\"1d\", \"2wk\", \"1mo\"}. Se refiere al intervalo para muestrear los datos: \"1d\"= diario, \"1wk\"= semanal, \"1mo\"=mensual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por ejemplo, usemos la función `get_data()` para obtener los datos asociados con la acción de **Apple** cuyo símbolo es `AAPL`, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usamos las funciones `set_theme()` para *configurar el tema a usar en las figuras*, en éste caso paper el cual invocamos usando `set_context(\"paper\")`. Para ver más temas para figuras con `seaborn` visitar [aesthetics](http://seaborn.pydata.org/tutorial/aesthetics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'AAPL'\n",
    "resolution = '1d'\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(date_h):\n",
    "    return date_h.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_df = get_data(stock, start_date=start_date, end_date=end_date, interval=resolution, index_as_date=False)\n",
    "AAPL_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizaremos la función `lineplot` de `seaborn` para realizar un gráfico de la serie de tiempo de interés. Nótese que se ha colocado `;` al final de éste llamado, *¿con que objetivo?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=AAPL_df, x=AAPL_df.date, y=AAPL_df.close);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Gráficos de velas en Python:** El gráfico de velas es un estilo de gráfico financiero que describe la apertura, el máximo, el mínimo y el cierre para una coordenada $x$ determinada (probablemente la hora). Los recuadros representan la dispersión entre los valores de apertura y cierre y las líneas representan la dispersión entre los valores bajos y altos. Los puntos de muestra en los que el valor de cierre es mayor (menor) que el de apertura se denominan crecientes (decrecientes).\n",
    "\n",
    "- Por defecto, las velas crecientes se dibujan en verde, mientras que las decrecientes se dibujan en rojo. Para realizar la figura usamos la función `Figure()` de la clase `go` de `plotly`, esta función recibe como input los datos asociados al candlestick suministrados por medio de la función `Candlestick` también de la clase `go` de `plotly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x = AAPL_df.date,\n",
    "                                     open = AAPL_df.open, \n",
    "                                     high = AAPL_df.high,\n",
    "                                     low = AAPL_df.low, \n",
    "                                     close = AAPL_df.close)\n",
    "                     ])\n",
    "fig.update_layout(\n",
    "    title=\"Apple Inc. (AAPL)\",\n",
    "    xaxis_title=\"Day\",\n",
    "    yaxis_title=\"AAPL-USD\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=12,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.update_layout(xaxis_rangeslider_visible=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizaremos ahora una prueba estadística para verificar si la serie de tiempo es estacionaria o no. Esta prueba es la de  `Dickey-Fuller`. En cursos avanzados de **series de tiempo** se estudian las matemáticas detrás de este tipo de pruebas así como los plots **ACF** y **PACF**, en esta sección solo mencionaremos en una bastante resumida la idea detrás de su uso.\n",
    "- Para hacer uso de esta prueba importamos la función `adfuller` de la clase `statsmodels.tsa.stattools`. Para aplicar el test pasamos los datos del precio de cierre, serie de tiempo de interés, usando `AAPL_df.close`. Este será el argumento de la función `adfuller` encargada de realizar el test de `Dickey-Fuller`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from numpy import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(AAPL_df.close)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El razonamiento asociado a esta prueba de hipótesis es basado en inferencia a partir del $p-$value. Si $p-$value > 0.05 no rechazamos nuestra hipótesis inicial con una significancia de 0.05\n",
    "\n",
    "$$\n",
    "H_{0}:\\text{la serie de tiempo es no estacionaria}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Realizaremos ahora figuras de **autocorrelación** para confirmar que la serie de tiempo diferenciada es estacionaria, así como también para verificar cuál es el orden de integración necesario para llevar nuestra serie de tiempo no estacionaria a una estacionaría. Para esto usaremos la función `plot_acf` de **Python**, la cual recibe como argumentos, la serie de tiempo de interés y el número de **lags** que deseamos considerar en la figura.\n",
    "- Nótese que utilizamos la función `.diff()` para realizar diferenciación en nuestra serie de tiempo, con el objetivo de remover tendencia, además nótese también que se eliminan valores `nan` que podamos obtener en este proceso debido a que esta figura consiste en representar todos los valores $\\rho_{k}$ definidos anteriormente, donde aparece un cociente para el cual evitamos valores nulos en el denominador.\n",
    "- Realizaremos tres figuras, correspondientes a la autocorrelación de la serie original, la serie diferenciada una vez, y dos veces. Colocaremos estas figuras en una matriz de $3\\times2$ usando la función `fig, axes = plt.subplots(3, 2, sharex=True)` de `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize': (15,15)})\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, sharex=True)\n",
    "axes[0, 0].plot(AAPL_df.close); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(AAPL_df.close, ax=axes[0, 1], lags = 240);\n",
    "\n",
    "axes[1, 0].plot(AAPL_df.close.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(AAPL_df.close.diff().dropna(), ax=axes[1, 1], lags = 240);\n",
    "\n",
    "axes[2, 0].plot(AAPL_df.close.diff().diff()); axes[2, 0].set_title('1st Order Differencing')\n",
    "plot_acf(AAPL_df.close.diff().diff().dropna(), ax=axes[2, 1], lags = 240);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nótese el **decaimiento geométrico** en la primera figura de autocorrelación, que baja desde la parte positiva con una tendencia lineal, el cual se interpreta como una *autocorrelación asociada a una serie de tiempo no estacionaría*, como indica la prueba de `Dickey-Fuller` que presenta efectivamente tendencias.\n",
    "- Los intervalos de confianza se dibujan como un cono. Por defecto, se establece un intervalo de confianza del 95%. Al observar el gráfico de autocorrelación para la segunda diferenciación, la *segunda autocorrelación entra en la zona negativa con bastante rapidez*, lo que indica que *la serie podría haber sido sobrediferenciada*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterios AIC, BIC, HQIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El `AIC, BIC, HQIC` utilizan la estimación de máxima verosimilitud (*Log Likelihood*) de un modelo como medida de ajuste. Los valores de `AIC, BIC, HQIC` son bajos para los modelos con *Log Likelihood* altos. Esto significa que el modelo se ajusta mejor a los datos, que es lo que queremos. Por ejemplo, `AIC` se define de la siguiente forma: $AIC=2k-2\\ln(L)$, donde $k$ es el `número de parámetros` en el modelo estadístico, y $L$ es el *máximo valor de la función de verosimilitud* para el modelo estimado. \n",
    "\n",
    "- Al ajustar modelos, es posible *aumentar la verosimilitud añadiendo parámetros*, pero *hacerlo puede dar lugar a un sobreajuste*. Tanto el `BIC` como el `AIC` intentan resolver este problema *introduciendo un término de penalización por el número de parámetros del modelo*; el término de penalización es mayor en el `BIC` que en el `AIC` para tamaños de muestra superiores a 7.\n",
    "\n",
    "- `BIC` está definido como $BIC=k\\ln(n)-2\\ln(L)$, donde aquí $n$ representa el tamaño de la muestra. El criterio de información de *Hannan–Quinn (HQIC)* está dado por $HQIC=2k\\ln(\\ln(n))-2\\ln(L)$. Este criterio reduce la penalización de `BIC`, de tal forma que en términos de penalización se ubica entre `AIC` y `BIC`. La selección del criterio va a depender del objetivo principal del investigador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_AAPL = len(AAPL_df.close); n_test = 28 # This can be changed\n",
    "train_size = n_AAPL - n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AAPL_df.close[:train_size]\n",
    "dates_train = AAPL_df.date[:train_size]\n",
    "test_4w = AAPL_df.close[train_size:train_size + n_test] \n",
    "dates_4w = AAPL_df.date[train_size:train_size + n_test] \n",
    "print(\"train:\", train.shape)\n",
    "print(\"test_4w:\", test_4w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = AAPL_df[[\"close\"]][:train_size]\n",
    "test_4w_df = AAPL_df[[\"close\"]][train_size:train_size + n_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4w_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utlizamos ahora el modelo `ARIMA` importado desde la librería `statsmodels` de **Python** para obetener distintos **ARIMA** de ordenes $p,d,q$. Consideramos `method = 'mle'` para el cálculo de la **verosimilitud** exacta a través del **filtro de Kalman**. Como ejercicio puede reescribir estas líneas de código en una función que dependa sólo del input `train` y retorne los ordenes $p, d, q$ asociados al criterio **AIC** de bondad de ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aic = np.inf\n",
    "best_bic = np.inf\n",
    "\n",
    "best_order = None\n",
    "best_mdl = None\n",
    "\n",
    "pq_rng = range(5)\n",
    "d_rng  = range(3)\n",
    "\n",
    "for i in pq_rng:\n",
    "    for d in d_rng:\n",
    "        for j in pq_rng:\n",
    "            try:\n",
    "                # print(i, d, j)\n",
    "                tmp_mdl = ARIMA(train, order=(i,d,j)).fit()\n",
    "                tmp_aic = tmp_mdl.aic\n",
    "                if tmp_aic < best_aic:\n",
    "                    best_aic = tmp_aic\n",
    "                    best_order = (i, d, j)\n",
    "                    best_mdl = tmp_mdl\n",
    "            except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('aic: {:6.5f} | order: {}'.format(best_aic, best_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Existe una función llamada `auto_arima` de **Python** la cual es útli en ciertos casos especificos. Éste no es uno de ellos dado que el modelo **ARIMA** que entrega es un simple random walk $x_{t}=x_{t-1}+\\omega_{t}$, el cual predice puramente como un modelo estocástico con dependencia temporal basado totalmente en el punto temporal anterior $t-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "model = pm.arima.auto_arima(train, start_p=1, start_q=1,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por lo tanto para éste problema consideramos los mejores ordenes $p, d, q$ obtenidos a a partir del criterio de Akaike. Los usamos como argumento de entrada en nuestro modelo **ARIMA** junto a nuestro *train set*, para obtener el modelo de ajustado de interés que utlizaremos para predecir valores futuros usando *rolling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ARIMA(train, order=best_order)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para graficar el ajuste de nuestro modelo **ARIMA** frente a nuestro conjunto de entrenamiento utilizamos la función `plot_predict` que proviene del objeto instanciado usando la función **ARIMA**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize': (10,6)})\n",
    "fig, ax = plt.subplots();\n",
    "plot_predict(model_fit, 1, ax=ax);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para medir el error de predicción cometido en las predicciones, utilizaremos las métricas usuales en análisis de series de tiempo: `MAPE, MAE, RMSE, MSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_accuracy(forecast, actual, str_name):\n",
    "    \n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual)) # MAPE\n",
    "    mae = np.mean(np.abs(forecast - actual))                 # MAE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5               # RMSE\n",
    "    mse = np.mean((forecast - actual)**2)                    # MSE\n",
    "    r2 = r2_score(forecast, actual)\n",
    "    \n",
    "    df_acc = pd.DataFrame({'MAE': [mae],\n",
    "                           'MSE': [mse],\n",
    "                           'MAPE': [mape],\n",
    "                           'RMSE': [rmse],\n",
    "                           'R2': [r2]},\n",
    "                          index=[str_name])\n",
    "    \n",
    "    return df_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Realizamos ahora predicciones utilizando *rolling forecasting*. El *rolling forecast* entrega reportes que utilizan datos históricos para predecir cifras futuras de forma continua durante un periodo de tiempo. Las previsiones continuas se utilizan a menudo en los reportes financieros, la gestión de la cadena de suministro, la planificación y la elaboración de presupuestos.\n",
    "- El *rolling forecast* es una ayuda esencial para tomar decisiones empresariales acertadas. Gracias a su capacidad de respuesta, las previsiones continuas ayudan a las empresas a responder más rápidamente a las condiciones cambiantes del mercado. Si se utilizan con eficacia, las previsiones continuas pueden ayudar a identificar las deficiencias de rendimiento, acortar los ciclos de planificación y tomar la mejor decisión para los resultados. Para nuestros ejemplos, nuestro horizonte de predicción será de un día"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/rolling.ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_rolling(history, test):\n",
    "    \n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=best_order)\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_4wl = test_4w.tolist()\n",
    "yhat_4w  = arima_rolling(train.tolist(), test_4wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizaremos ahora las funciones creadas anteriormente para calcular el error de predicción y `lineplot` para graficarle junto a la serie de tiempo original de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_accuracy(np.array(test_4wl), np.array(yhat_4w), \"week 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x=dates_train[-100:], y=train[-100:], label=\"Train\", color='g')\n",
    "sns.lineplot(x=dates_4w, y=test_4wl, label=\"Test\", color='b')\n",
    "sns.lineplot(x=dates_4w, y=yhat_4w, label=\"Forecast\", color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "- Cuando se utiliza ***rolling forecasting*** en la predicción de series temporales, ***es posible que se encuentren valores de*** $R^{2}$ ***negativos para horizontes de predicción pequeños*** debido a varias razones:\n",
    "\n",
    "    - ***Datos Limitados***: Con un horizonte de predicción pequeño, puede haber una ***cantidad limitada de datos disponibles para que el modelo capture con precisión los patrones subyacentes en la serie temporal***. Esta limitación puede conducir a predicciones menos confiables, lo que resulta en valores de $R^{2}$ negativos.\n",
    "    \n",
    "    - ***Sobreajuste del Modelo***: Para horizontes de predicción pequeños, ***el modelo puede volverse demasiado complejo y ajustarse demasiado a la aleatoriedad o las fluctuaciones en los datos en lugar de la tendencia subyacente***. Este sobreajuste puede hacer que las predicciones del modelo funcionen mal cuando se aplican a nuevos datos, lo que resulta en valores de $R^{2}$ negativos.\n",
    "    \n",
    "    - ***Variación Aleatoria***: En los datos de series temporales, ***puede haber una aleatoriedad inherente o variabilidad que el modelo no logra capturar, especialmente con un horizonte de predicción pequeño***. Como resultado, las predicciones del modelo pueden desviarse significativamente de los valores reales, lo que lleva a valores de $R^{2} negativos.\n",
    "    \n",
    "    - ***Error de Medición***: Los ***horizontes de predicción pequeños pueden amplificar los errores de medición o las inexactitudes en los datos***, lo que lleva a un peor rendimiento del modelo y valores de $R^{2}$ negativos.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio para entregar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Considere la serie de tiempo asociada con los futuros de la criptomoneda **Bitcoin** desde que comenzó a comercializarse hasta la fecha del día de hoy. Utilice la **API** de `Yahoo Finance` para obtener esta serie de tiempo.\n",
    "\n",
    "2. Repita **TODOS** los pasos indicados en esta sección para encontrar modelos **ARIMA** para predecir el precio de **Bitcoin** con los siguientes horizontes: **7, 14, 21 y 28 días**. Utilizar siempre predicciones usando *rolling* con ventana de predicción continua de un día. Cualquier cantidad de pasos extra para enriquecer su análisis predictivo serán aceptados siempre y cuando sean acordes con lo que indica la teoría de análisis de series de tiempo. \n",
    "\n",
    "````{figure} ./figures/homework_timeseries_dataviz.png\n",
    ":name: homework_timeseries_dataviz_fig\n",
    ":align: center\n",
    ":scale: 24\n",
    "````\n",
    "\n",
    "3. Repita el paso 2 ahora **sin utilizar rolling**. Esto es, realice el pronóstico solo utilizando `forecast()` para los diferentes horizontes de predicción, **7, 14, 21 y 28 días**.\n",
    "\n",
    "4. Realice tablas de error para los ítems 1 y 2, utilizando las métricas: `MAPE, MAE, RMSE, MSE, R2`. Además, agregue el gráfico de correlación entre la observación real y su predicción en el test, $\\text{Corr}(y_{t}, \\tilde{y}_{t})$.\n",
    "\n",
    "5. Repita el análisis desarrollado en los pasos anteriores, considerando ahora el criterio de **inferencia Bayesiana (BIC)** y el criterio de información de **Hannan–Quinn (HQIC)** para encontrar el mejor modelo **ARIMA** y, compare los errores con aquellos obtenidos con el criterio de **Akaike**.\n",
    "\n",
    "6. Escriba en cada paso las **conclusiones** y **análisis estadísticos** asociados con los resultados obtenidos. Realice **tests de normalidad e independencia para los residuales** obtenidos para cada predicción, en cada caso agregue las correspondientes conclusiones. Figuras y algoritmos que no estén acompañados de una conclusión, descripción y análisis estadístico, no serán tenidas en cuenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_tf",
   "language": "python",
   "name": "ml_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenido",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "432.667px",
    "left": "10px",
    "top": "150px",
    "width": "158.333px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
